{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Logit` on Orders - A warm-up challenge (~1h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Let's figure out the impact of `wait_time` and `delay_vs_expected` on very `good/bad reviews`\n",
    "\n",
    "üëâ Using our `orders` training_set, we will run two `multivariate logistic regressions`:\n",
    "- `logit_one` to predict `dim_is_one_star` \n",
    "- `logit_five` to predict `dim_is_five_star`.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Import your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olist.order import Order\n",
    "orders = Order().get_training_data(with_distance_seller_customer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Select in a list which features you want to use:\n",
    "\n",
    "‚ö†Ô∏è Make sure you are not creating data leakage (i.e. selecting features that are derived from the target)\n",
    "\n",
    "üí° To figure out the impact of `wait_time` and `delay_vs_expected` we need to control for the impact of other features, include in your list all features that may be relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274497\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637411\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        dim_is_one_star   No. Observations:                95872\n",
      "Model:                          Logit   Df Residuals:                    95865\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Wed, 08 Nov 2023   Pseudo R-squ.:                  0.1419\n",
      "Time:                        18:20:52   Log-Likelihood:                -26317.\n",
      "converged:                       True   LL-Null:                       -30669.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept             -5.3069      0.070    -75.412      0.000      -5.445      -5.169\n",
      "wait_time              0.0650      0.002     40.296      0.000       0.062       0.068\n",
      "delay_vs_expected      0.0691      0.004     17.866      0.000       0.061       0.077\n",
      "number_of_products     0.5074      0.020     25.528      0.000       0.468       0.546\n",
      "number_of_sellers      1.4186      0.063     22.378      0.000       1.294       1.543\n",
      "price                  0.0003   5.46e-05      5.184      0.000       0.000       0.000\n",
      "freight_value         -0.0033      0.001     -5.123      0.000      -0.005      -0.002\n",
      "======================================================================================\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       dim_is_five_star   No. Observations:                95872\n",
      "Model:                          Logit   Df Residuals:                    95865\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Wed, 08 Nov 2023   Pseudo R-squ.:                 0.05720\n",
      "Time:                        18:20:52   Log-Likelihood:                -61110.\n",
      "converged:                       True   LL-Null:                       -64817.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept              2.4664      0.064     38.349      0.000       2.340       2.593\n",
      "wait_time             -0.0493      0.001    -44.871      0.000      -0.052      -0.047\n",
      "delay_vs_expected     -0.1036      0.005    -20.748      0.000      -0.113      -0.094\n",
      "number_of_products    -0.2778      0.016    -17.895      0.000      -0.308      -0.247\n",
      "number_of_sellers     -1.1453      0.063    -18.088      0.000      -1.269      -1.021\n",
      "price               7.778e-05   3.68e-05      2.115      0.034    5.69e-06       0.000\n",
      "freight_value          0.0015      0.000      3.680      0.000       0.001       0.002\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from olist.order import Order\n",
    "orders = Order().get_training_data(with_distance_seller_customer=True)\n",
    "\n",
    "relevant_features = [\n",
    "    'wait_time', \n",
    "    'delay_vs_expected', \n",
    "    'number_of_products', \n",
    "    'number_of_sellers', \n",
    "    'price', \n",
    "    'freight_value'\n",
    "]\n",
    "\n",
    "\n",
    "formula_one_star = 'dim_is_one_star ~ ' + ' + '.join(relevant_features)\n",
    "formula_five_star = 'dim_is_five_star ~ ' + ' + '.join(relevant_features)\n",
    "logit_one = smf.logit(formula=formula_one_star, data=orders).fit()\n",
    "logit_five = smf.logit(formula=formula_five_star, data=orders).fit()\n",
    "\n",
    "print(logit_one.summary())\n",
    "print(logit_five.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üïµüèª Check the `multi-colinearity` of your features, using the `VIF index`.\n",
    "\n",
    "* It shouldn't be too high (< 10 preferably) to ensure that we can trust the partial regression coefficents and their associated `p-values` \n",
    "* Do not forget to standardize your data ! \n",
    "    * A `VIF Analysis` is made by regressing a feature vs. the other features...\n",
    "    * So you want to `remove the effect of scale` so that your features have an equal importance before running any linear regression!\n",
    "    \n",
    "    \n",
    "üìö <a href=\"https://www.statisticshowto.com/variance-inflation-factor/\">Statistics How To - Variance Inflation Factor</a>\n",
    "\n",
    "üìö  <a href=\"https://online.stat.psu.edu/stat462/node/180/\">PennState - Detecting Multicollinearity Using Variance Inflation Factors</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öñÔ∏è Standardizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              feature       VIF\n",
      "0               const  1.000000\n",
      "1           wait_time  2.104346\n",
      "2   delay_vs_expected  2.022291\n",
      "3  number_of_products  1.343611\n",
      "4   number_of_sellers  1.093128\n",
      "5               price  1.204782\n",
      "6       freight_value  1.541776\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "features_for_vif = orders[[\n",
    "    'wait_time', \n",
    "    'delay_vs_expected', \n",
    "    'number_of_products', \n",
    "    'number_of_sellers', \n",
    "    'price', \n",
    "    'freight_value'\n",
    "]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_for_vif)\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features_for_vif.columns)\n",
    "scaled_features_df_with_constant = sm.add_constant(scaled_features_df)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = scaled_features_df_with_constant.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(scaled_features_df_with_constant.values, i)\n",
    "                   for i in range(scaled_features_df_with_constant.shape[1])]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Run your VIF Analysis to analyze the potential multicolinearities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The VIF for const is 1.00, suggesting no multicollinearity.\n",
      "The VIF for wait_time is 2.10, suggesting no multicollinearity.\n",
      "The VIF for delay_vs_expected is 2.02, suggesting no multicollinearity.\n",
      "The VIF for number_of_products is 1.34, suggesting no multicollinearity.\n",
      "The VIF for number_of_sellers is 1.09, suggesting no multicollinearity.\n",
      "The VIF for price is 1.20, suggesting no multicollinearity.\n",
      "The VIF for freight_value is 1.54, suggesting no multicollinearity.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_vif(dataframe, features):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(dataframe[features])\n",
    "    scaled_features_df = pd.DataFrame(scaled_features, columns=features)\n",
    "    scaled_features_df_with_constant = sm.add_constant(scaled_features_df)\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = scaled_features_df_with_constant.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(scaled_features_df_with_constant.values, i)\n",
    "                       for i in range(scaled_features_df_with_constant.shape[1])]\n",
    "    \n",
    "    return vif_data\n",
    "\n",
    "features = [\n",
    "    'wait_time', \n",
    "    'delay_vs_expected', \n",
    "    'number_of_products', \n",
    "    'number_of_sellers', \n",
    "    'price', \n",
    "    'freight_value'\n",
    "]\n",
    "\n",
    "vif_data = calculate_vif(orders, features)\n",
    "\n",
    "for index, row in vif_data.iterrows():\n",
    "    print(f\"The VIF for {row['feature']} is {row['VIF']:.2f}, suggesting {'no' if row['VIF'] < 10 else 'significant'} multicollinearity.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Fit two `Logistic Regression` models:\n",
    "- `logit_one` to predict `dim_is_one_star` \n",
    "- `logit_five` to predict `dim_is_five_star`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Logit 1Ô∏è‚É£`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274497\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        dim_is_one_star   No. Observations:                95872\n",
      "Model:                          Logit   Df Residuals:                    95865\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Wed, 08 Nov 2023   Pseudo R-squ.:                  0.1419\n",
      "Time:                        18:31:57   Log-Likelihood:                -26317.\n",
      "converged:                       True   LL-Null:                       -30669.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept             -5.3069      0.070    -75.412      0.000      -5.445      -5.169\n",
      "wait_time              0.0650      0.002     40.296      0.000       0.062       0.068\n",
      "delay_vs_expected      0.0691      0.004     17.866      0.000       0.061       0.077\n",
      "number_of_products     0.5074      0.020     25.528      0.000       0.468       0.546\n",
      "number_of_sellers      1.4186      0.063     22.378      0.000       1.294       1.543\n",
      "price                  0.0003   5.46e-05      5.184      0.000       0.000       0.000\n",
      "freight_value         -0.0033      0.001     -5.123      0.000      -0.005      -0.002\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "formula_one_star = 'dim_is_one_star ~ wait_time + delay_vs_expected + number_of_products + number_of_sellers + price + freight_value'\n",
    "logit_one = smf.logit(formula=formula_one_star, data=orders).fit()\n",
    "print(logit_one.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Logit 5Ô∏è‚É£`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637411\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       dim_is_five_star   No. Observations:                95872\n",
      "Model:                          Logit   Df Residuals:                    95865\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Wed, 08 Nov 2023   Pseudo R-squ.:                 0.05720\n",
      "Time:                        18:31:37   Log-Likelihood:                -61110.\n",
      "converged:                       True   LL-Null:                       -64817.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept              2.4664      0.064     38.349      0.000       2.340       2.593\n",
      "wait_time             -0.0493      0.001    -44.871      0.000      -0.052      -0.047\n",
      "delay_vs_expected     -0.1036      0.005    -20.748      0.000      -0.113      -0.094\n",
      "number_of_products    -0.2778      0.016    -17.895      0.000      -0.308      -0.247\n",
      "number_of_sellers     -1.1453      0.063    -18.088      0.000      -1.269      -1.021\n",
      "price               7.778e-05   3.68e-05      2.115      0.034    5.69e-06       0.000\n",
      "freight_value          0.0015      0.000      3.680      0.000       0.001       0.002\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the formula for the logistic regression model to predict five-star reviews\n",
    "formula_five_star = 'dim_is_five_star ~ wait_time + delay_vs_expected + number_of_products + number_of_sellers + price + freight_value'\n",
    "\n",
    "# Fit the logistic regression model to predict five-star reviews\n",
    "logit_five = smf.logit(formula=formula_five_star, data=orders).fit()\n",
    "\n",
    "# Print the summary of the model for five-star reviews\n",
    "print(logit_five.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° It's time to analyse the results of these two logistic regressions:\n",
    "\n",
    "- Interpret the partial coefficients in your own words.\n",
    "- Check their statistical significances with `p-values`\n",
    "- Do you notice any differences between `logit_one` and `logit_five` in terms of coefficient importances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['delay_vs_expected influences five_star ratings even more than one_star ratings']\n"
     ]
    }
   ],
   "source": [
    "# Among the following sentences, store the ones that are true in the list below\n",
    "\n",
    "a = \"delay_vs_expected influences five_star ratings even more than one_star ratings\"\n",
    "b = \"wait_time influences five_star ratings even more more than one_star\"\n",
    "\n",
    "your_answer = []\n",
    "\n",
    "# Add the true statements based on the analysis\n",
    "if logit_five.params['delay_vs_expected'] < logit_one.params['delay_vs_expected']:\n",
    "    your_answer.append(a)\n",
    "if abs(logit_five.params['wait_time']) > abs(logit_one.params['wait_time']):\n",
    "    your_answer.append(b)\n",
    "\n",
    "print(your_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ __Test your code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/francoisgirard/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/francoisgirard/code/francoisgirard51/04-Decision-Science/04-Logistic-Regression/data-logit/tests\n",
      "plugins: asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_logit.py::TestLogit::test_question \u001b[32mPASSED\u001b[0m\u001b[32m                           [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/logit.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed logit step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('logit',\n",
    "    answers = your_answer\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>- <i>Explanations and advanced concepts </i> -</summary>\n",
    "\n",
    "\n",
    "> _All other thing being equal, the `delay factor` tends to increase the chances of getting stripped of the 5-star even more so than it affect the chances of 1-star reviews. Probably because 1-stars are really targeting bad products themselves, not bad deliveries_\n",
    "    \n",
    "‚ùóÔ∏è However, to be totally rigorous, we have to be **more careful when comparing coefficients from two different models**, because **they might not be based on similar populations**!\n",
    "    We have 2 sub-populations here: (people who gave 1-stars; and people who gave 5-stars) and they may exhibit intrinsically different behavior patterns. It may well be that \"happy-people\" (who tends to give 5-stars easily) are less sensitive as \"grumpy-people\" (who shoot 1-stars like Lucky-Luke), when it comes to \"delay\", or \"price\"...\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic vs. Linear ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Compare the coefficients obtained from:\n",
    "- A `Logistic Regression` to explain `dim_is_five_star`\n",
    "- A `Linear Regression` to explain `review_score` \n",
    "\n",
    "Make sure to use the same set of features for both regressions.  \n",
    "\n",
    "‚ö†Ô∏è Check that both sets of coefficients  tell  \"the same story\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! \n",
    "\n",
    "üíæ Don't forget to commit and push your `logit.ipynb` notebook !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
